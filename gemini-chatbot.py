# -*- coding: utf-8 -*-
"""Hello World Google LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lt_9ay8DzBGawRubPYPVsG2bKfDfM9SS
"""

# Prompting LLM
#1. API Key
#2. Model
#3. Prompt
#4 SDK - Google SDK or Framework or Langchain

import os

#from google.colab import userdata
#os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')
from dotenv import load_dotenv
load_dotenv()

model = 'gemini-2.5-flash'
prompt = 'Who are you?'

# Commented out IPython magic to ensure Python compatibility.
# %pip install -qU google-generativeai

from google import genai

client = genai.Client()



def generate_response(user_input):
    response = client.models.generate_content(
        model=model,
        contents=user_input,
    )
    return response.text

if __name__ == "__main__":
    response = client.models.generate_content(
        model=model,
        contents=prompt,
    )
    print(response.text)
    
    input_tokens = response.usage_metadata.prompt_token_count
    output_tokens = response.usage_metadata.prompt_tokens_details
    candidate_token = response.usage_metadata.candidates_token_count

    print(f'Input Tokens: {input_tokens}')
    print(f'Output Tokens: {output_tokens}')
    print(f'Candidate Tokens: {candidate_token}')

    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            break
        bot_response = generate_response(user_input)
        print(f"Bot: {bot_response}")